{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding t-SNE visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ben Greenawald (bhg5yd)\n",
    "Based on https://www.kaggle.com/jeffd23/visualizing-word-vectors-with-t-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgree\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "import os\n",
    "import progressbar\n",
    "import pickle\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to clean sentences\n",
    "STOP_WORDS = nltk.corpus.stopwords.words()\n",
    "\n",
    "def clean_sentence(val):\n",
    "    \"remove chars that are not letters or numbers, downcase, then remove stop words\"\n",
    "    regex = re.compile('([^\\s\\w]|_)+')\n",
    "    sentence = regex.sub('', val).lower()\n",
    "    sentence = sentence.split(\" \")\n",
    "    \n",
    "    for word in list(sentence):\n",
    "        if word in STOP_WORDS:\n",
    "            sentence.remove(word)  \n",
    "            \n",
    "    sentence = \" \".join(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| 5502 Elapsed Time: 0:10:16                                                   \n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "data_path = \"C:\\\\Users\\\\bgree\\\\Documents\\\\capstone\\\\Eng\\\\eng_clean\\\\\"\n",
    "\n",
    "# Read in all files\n",
    "sentences = [0] * len(os.listdir(data_path)) \n",
    "files = [0] * len(os.listdir(data_path)) \n",
    "bar = progressbar.ProgressBar()\n",
    "\n",
    "for i, file in bar(enumerate(os.listdir(data_path))):\n",
    "    with open((data_path + file), \"r\") as cur_file:\n",
    "        sentences[i] = clean_sentence(cur_file.read())\n",
    "        files[i] = file\n",
    "        cur_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace newlines with spaces, replace multiple spaces with single space\n",
    "newline = re.compile(\"[\\n]+\")\n",
    "multispace = re.compile(\"[ ]+\")\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    sentence = newline.sub(' ', sentence)\n",
    "    sentence = multispace.sub(' ', sentence)\n",
    "    sentences[i] = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickle the list so we don't have to read it in again\n",
    "with open('C:\\\\Users\\\\bgree\\\\Documents\\\\capstone\\\\Eng\\\\sentences.pkl', 'wb') as f:\n",
    "    pickle.dump(sentences, f)\n",
    "    f.close()\n",
    "    \n",
    "with open('C:\\\\Users\\\\bgree\\\\Documents\\\\capstone\\\\Eng\\\\files.pkl', 'wb') as f:\n",
    "    pickle.dump(files, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\bgree\\\\Documents\\\\capstone\\\\Eng\\\\sentences.pkl', 'rb') as f:\n",
    "    sentences = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "with open('C:\\\\Users\\\\bgree\\\\Documents\\\\capstone\\\\Eng\\\\files.pkl', 'rb') as f:\n",
    "    files = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_corpus(data):\n",
    "    \"Creates a list of lists containing words from each sentence\"\n",
    "    corpus = [0] * len(data)\n",
    "    for i, sentence in enumerate(data):\n",
    "        word_list = sentence.split(\" \")\n",
    "        corpus[i] = word_list\n",
    "            \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = build_corpus(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(corpus, size=100, window=5, min_count=50, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"C:\\\\Users\\\\bgree\\\\Documents\\\\capstone\\\\Eng\\\\model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec.load(\"C:\\\\Users\\\\bgree\\\\Documents\\\\capstone\\\\Eng\\\\model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('feed', 0.4436623752117157),\n",
       " ('save', 0.42832493782043457),\n",
       " ('physically', 0.38688328862190247),\n",
       " ('death', 0.382870078086853),\n",
       " ('drown', 0.371822327375412),\n",
       " ('heal', 0.36274629831314087),\n",
       " ('restore', 0.359414279460907),\n",
       " ('recover', 0.35854101181030273),\n",
       " ('starve', 0.35682594776153564),\n",
       " ('killed', 0.35319411754608154)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['kill', 'love'], negative=['hate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nurse', 0.6744319200515747),\n",
       " ('hospital', 0.6417989134788513),\n",
       " ('patients', 0.6167763471603394),\n",
       " ('doctors', 0.5895438194274902),\n",
       " ('clinic', 0.5791116952896118),\n",
       " ('shane', 0.5531526803970337),\n",
       " ('mom', 0.5406304597854614),\n",
       " ('sick', 0.5246722102165222),\n",
       " ('surgery', 0.5209794044494629),\n",
       " ('teenager', 0.5186388492584229)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['doctor', 'woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wife', 0.770444393157959),\n",
       " ('wives', 0.5845280289649963),\n",
       " ('zainab', 0.5403890013694763),\n",
       " ('husbands', 0.539920449256897),\n",
       " ('marriage', 0.5272690057754517),\n",
       " ('daughter', 0.5203981399536133),\n",
       " ('women', 0.5176483392715454),\n",
       " ('divorced', 0.4951685070991516),\n",
       " ('nurse', 0.49472132325172424),\n",
       " ('unmarried', 0.48751023411750793)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['husband', 'woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('doomed', 0.4933154582977295),\n",
       " ('nation', 0.47456789016723633),\n",
       " ('patriotic', 0.46974021196365356),\n",
       " ('continent', 0.45280495285987854),\n",
       " ('civilization', 0.43584635853767395),\n",
       " ('democracy', 0.4354703724384308),\n",
       " ('europe', 0.4346542954444885),\n",
       " ('anglo', 0.42719873785972595),\n",
       " ('liberalism', 0.4231260418891907),\n",
       " ('eastern', 0.41540855169296265)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['america'], negative=['money'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('swedish', 0.750615656375885),\n",
       " ('banned', 0.7378867268562317),\n",
       " ('danish', 0.7345162630081177),\n",
       " ('northeast', 0.724465012550354),\n",
       " ('dutch', 0.7241246700286865),\n",
       " ('switzerland', 0.7159587144851685),\n",
       " ('caribbean', 0.7075758576393127),\n",
       " ('quebec', 0.7073105573654175),\n",
       " ('indonesia', 0.7058912515640259),\n",
       " ('infamous', 0.7054986953735352)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['sweden'], negative=['hope'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tsne_plot(model):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.vocab:\n",
    "        tokens.append(model[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(n_components=2, random_state=23, verbose=3)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    d = {\"x\": x, \n",
    "         \"y\":y,\n",
    "         \"words\": labels}\n",
    "    \n",
    "    return pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgree\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 12050 samples in 0.053s...\n",
      "[t-SNE] Computed neighbors for 12050 samples in 30.726s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 12050\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 12050\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 12050\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 12050\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 12050\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 12050\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 12050\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 12050\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 12050\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 12050\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 12050\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 12050\n",
      "[t-SNE] Computed conditional probabilities for sample 12050 / 12050\n",
      "[t-SNE] Mean sigma: 0.840219\n",
      "[t-SNE] Computed conditional probabilities in 0.454s\n",
      "[t-SNE] Iteration 50: error = 95.0885773, gradient norm = 0.0373409 (50 iterations in 28.079s)\n",
      "[t-SNE] Iteration 100: error = 95.2065125, gradient norm = 0.0108383 (50 iterations in 26.733s)\n",
      "[t-SNE] Iteration 150: error = 95.0272827, gradient norm = 0.0085695 (50 iterations in 25.674s)\n",
      "[t-SNE] Iteration 200: error = 95.0035629, gradient norm = 0.0427824 (50 iterations in 22.085s)\n",
      "[t-SNE] Iteration 250: error = 94.7399826, gradient norm = 0.0274619 (50 iterations in 22.349s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 94.739983\n",
      "[t-SNE] Iteration 300: error = 3.7992411, gradient norm = 0.0010491 (50 iterations in 22.745s)\n",
      "[t-SNE] Iteration 350: error = 3.4868751, gradient norm = 0.0004958 (50 iterations in 20.981s)\n",
      "[t-SNE] Iteration 400: error = 3.3391721, gradient norm = 0.0002962 (50 iterations in 21.097s)\n",
      "[t-SNE] Iteration 450: error = 3.2469645, gradient norm = 0.0002031 (50 iterations in 20.942s)\n",
      "[t-SNE] Iteration 500: error = 3.1837416, gradient norm = 0.0001507 (50 iterations in 20.739s)\n",
      "[t-SNE] Iteration 550: error = 3.1376946, gradient norm = 0.0001189 (50 iterations in 20.684s)\n",
      "[t-SNE] Iteration 600: error = 3.1019511, gradient norm = 0.0000989 (50 iterations in 20.834s)\n",
      "[t-SNE] Iteration 650: error = 3.0739489, gradient norm = 0.0000832 (50 iterations in 20.912s)\n",
      "[t-SNE] Iteration 700: error = 3.0515647, gradient norm = 0.0000730 (50 iterations in 20.867s)\n",
      "[t-SNE] Iteration 750: error = 3.0331788, gradient norm = 0.0000623 (50 iterations in 20.903s)\n",
      "[t-SNE] Iteration 800: error = 3.0179467, gradient norm = 0.0000548 (50 iterations in 20.877s)\n",
      "[t-SNE] Iteration 850: error = 3.0050015, gradient norm = 0.0000497 (50 iterations in 21.484s)\n",
      "[t-SNE] Iteration 900: error = 2.9941509, gradient norm = 0.0000445 (50 iterations in 20.479s)\n",
      "[t-SNE] Iteration 950: error = 2.9848399, gradient norm = 0.0000413 (50 iterations in 20.628s)\n",
      "[t-SNE] Iteration 1000: error = 2.9770401, gradient norm = 0.0000407 (50 iterations in 21.066s)\n",
      "[t-SNE] Error after 1000 iterations: 2.977040\n"
     ]
    }
   ],
   "source": [
    "tsne_data = tsne_plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne_data.to_csv(\"wordTSNE.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the document labels\n",
    "group_to_labels = {}\n",
    "with open(\"C:\\\\Users\\\\bgree\\\\Documents\\\\capstone\\\\Eng\\\\eng_group_labels.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        line_split = line.split(\",\")\n",
    "        group_to_labels[line_split[0]] = int(line_split[1])\n",
    "        \n",
    "# Get the filenames and labels\n",
    "digit_remover = re.compile(\"[\\d]+\")\n",
    "\n",
    "groups_labels = [0] * len(sentences)\n",
    "binary_labels = [0] * len(sentences)\n",
    "for i, file in enumerate(files):\n",
    "    f = file.split('.')[0]\n",
    "    f = digit_remover.sub('',f)\n",
    "    if f[-1] == '-':\n",
    "        f = f[:-1]\n",
    "    if f == 'AndrewMurray-HolyinChrist':\n",
    "        f = 'AndrewMurray'\n",
    "    groups_labels[i] = f\n",
    "    binary_labels[i] = group_to_labels[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = [0] * len(sentences)\n",
    "for i, doc in enumerate(sentences):\n",
    "     str_list = doc.split()\n",
    "     t = doc2vec.TaggedDocument(str_list,[i])\n",
    "     docs[i] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgree\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "modelDoc = doc2vec.Doc2Vec(docs, size=100, window=8, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelDoc.save(\"C:\\\\Users\\\\bgree\\\\Documents\\\\capstone\\\\Eng\\\\modelDoc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelDoc = word2vec.Word2Vec.load(\"C:\\\\Users\\\\bgree\\\\Documents\\\\capstone\\\\Eng\\\\modelDoc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tsne_doc(model):\n",
    "    docs = []\n",
    "    for i in range(5503):\n",
    "        docs.append(model.docvecs[i])\n",
    "    \n",
    "    tsne_model = TSNE(n_components=2, random_state=23, verbose=3)\n",
    "    new_values = tsne_model.fit_transform(docs)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    d = {\"x\": x, \n",
    "         \"y\":y\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 5503 samples in 0.026s...\n",
      "[t-SNE] Computed neighbors for 5503 samples in 4.106s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 5503\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 5503\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 5503\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 5503\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 5503\n",
      "[t-SNE] Computed conditional probabilities for sample 5503 / 5503\n",
      "[t-SNE] Mean sigma: 0.663664\n",
      "[t-SNE] Computed conditional probabilities in 0.174s\n",
      "[t-SNE] Iteration 50: error = 85.7676392, gradient norm = 0.0452217 (50 iterations in 12.517s)\n",
      "[t-SNE] Iteration 100: error = 85.8437500, gradient norm = 0.0302953 (50 iterations in 12.008s)\n",
      "[t-SNE] Iteration 150: error = 85.8016357, gradient norm = 0.0296729 (50 iterations in 21.506s)\n",
      "[t-SNE] Iteration 200: error = 85.6228256, gradient norm = 0.0444155 (50 iterations in 16.705s)\n",
      "[t-SNE] Iteration 250: error = 85.8885422, gradient norm = 0.0217182 (50 iterations in 21.924s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 85.888542\n",
      "[t-SNE] Iteration 300: error = 3.1420171, gradient norm = 0.0011750 (50 iterations in 8.788s)\n",
      "[t-SNE] Iteration 350: error = 2.9393091, gradient norm = 0.0004231 (50 iterations in 7.456s)\n",
      "[t-SNE] Iteration 400: error = 2.8492389, gradient norm = 0.0002322 (50 iterations in 7.289s)\n",
      "[t-SNE] Iteration 450: error = 2.7987199, gradient norm = 0.0001576 (50 iterations in 7.367s)\n",
      "[t-SNE] Iteration 500: error = 2.7663517, gradient norm = 0.0001258 (50 iterations in 7.428s)\n",
      "[t-SNE] Iteration 550: error = 2.7449746, gradient norm = 0.0001032 (50 iterations in 7.398s)\n",
      "[t-SNE] Iteration 600: error = 2.7301342, gradient norm = 0.0000828 (50 iterations in 7.362s)\n",
      "[t-SNE] Iteration 650: error = 2.7193618, gradient norm = 0.0000730 (50 iterations in 7.388s)\n",
      "[t-SNE] Iteration 700: error = 2.7119226, gradient norm = 0.0000668 (50 iterations in 7.392s)\n",
      "[t-SNE] Iteration 750: error = 2.7062137, gradient norm = 0.0000568 (50 iterations in 7.366s)\n",
      "[t-SNE] Iteration 800: error = 2.7013857, gradient norm = 0.0000533 (50 iterations in 7.862s)\n",
      "[t-SNE] Iteration 850: error = 2.6975021, gradient norm = 0.0000483 (50 iterations in 8.152s)\n",
      "[t-SNE] Iteration 900: error = 2.6941586, gradient norm = 0.0000478 (50 iterations in 8.685s)\n",
      "[t-SNE] Iteration 950: error = 2.6914542, gradient norm = 0.0000470 (50 iterations in 8.250s)\n",
      "[t-SNE] Iteration 1000: error = 2.6893280, gradient norm = 0.0000584 (50 iterations in 8.069s)\n",
      "[t-SNE] Error after 1000 iterations: 2.689328\n"
     ]
    }
   ],
   "source": [
    "tsne_data2 = tsne_doc(modelDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne_data2['binary'] = binary_labels\n",
    "tsne_data2['group'] = groups_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne_data2.to_csv(\"docTSNE.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
